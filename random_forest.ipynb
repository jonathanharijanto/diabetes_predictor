{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Train Features: --> len: 82433\n",
      "\n",
      "[[28269 28269 92610462 ... 0 1 0]\n",
      " [56909 56909 162968724 ... 1 1 2]\n",
      " [56503 56503 162206526 ... 1 1 1]\n",
      " ...\n",
      " [70671 70671 203166414 ... 1 1 0]\n",
      " [12809 12809 51725166 ... 1 1 1]\n",
      " [3845 3845 22872546 ... 1 1 0]]\n",
      "\n",
      "2. Train Labels: --> len: 82433\n",
      "\n",
      "[0 2 0 ... 2 2 1]\n",
      "\n",
      "3. Valid Features: --> len: 9158\n",
      "\n",
      "[[101247 101247 436765574 ... 0 1 0]\n",
      " [2348 2348 15446892 ... 0 1 1]\n",
      " [11505 11505 47518116 ... 0 1 1]\n",
      " ...\n",
      " [89452 89452 289020042 ... 0 1 0]\n",
      " [101385 101385 438529178 ... 0 0 0]\n",
      " [23280 23280 79571748 ... 1 1 1]]\n",
      "\n",
      "4. Valid Labels: --> len: 9158\n",
      "\n",
      "[0 0 0 ... 1 1 1]\n",
      "\n",
      "5. Test Features: --> len: 10175\n",
      "\n",
      "[[51502 51502 153548118 ... 0 1 1]\n",
      " [8046 8046 37023612 ... 1 1 2]\n",
      " [50255 50255 151121442 ... 0 1 0]\n",
      " ...\n",
      " [85073 85073 269113332 ... 0 0 2]\n",
      " [8332 8332 37870290 ... 0 0 2]\n",
      " [40701 40701 126311478 ... 1 1 1]]\n",
      "\n",
      "6. Test Labels: --> len: 10175\n",
      "\n",
      "[0 0 0 ... 1 1 1]\n",
      "\n",
      "7. Label Dict: --> len: 3\n",
      "\n",
      "{'no': 0, '<30': 1, '>30': 2}\n"
     ]
    }
   ],
   "source": [
    "import data_loader\n",
    "import numpy as np\n",
    "\n",
    "the_data = data_loader.load_dataset(\"dataset_diabetes/diabetes_data_preprocessed.csv\")\n",
    "outputs = [\"1. Train Features:\", \"2. Train Labels:\", \"3. Valid Features:\", \"4. Valid Labels:\", \"5. Test Features:\", \"6. Test Labels:\", \"7. Label Dict:\"]\n",
    "\n",
    "for i in range(len(the_data)):\n",
    "    print(\"\\n\" + outputs[i] + \" --> len: \" + str(len(the_data[i])) + \"\\n\\n\" + str(the_data[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = the_data[0]\n",
    "Y_train = the_data[1]\n",
    "\n",
    "X_val = the_data[2]\n",
    "Y_val = the_data[3]\n",
    "\n",
    "X_test = the_data[4]\n",
    "Y_test = the_data[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation score: 50.97%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dte = DecisionTreeClassifier(max_depth=28, min_samples_split=10)\n",
    "scores = cross_val_score(dte, X_train, Y_train, cv=10)\n",
    "print(\"Cross Validation score: {:.2%}\".format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.50\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Target is multiclass but average='binary'. Please choose another average setting.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-a6392eb74b49>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Accuracy is {0:.2f}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_val_predict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Precision is {0:.2f}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprecision_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_val_predict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Recall is {0:.2f}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecall_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_val_predict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"AUC is {0:.2f}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_val_predict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36mprecision_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[0;32m   1259\u001b[0m                                                  \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1260\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'precision'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1261\u001b[1;33m                                                  sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m   1262\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight)\u001b[0m\n\u001b[0;32m   1038\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1039\u001b[0m             raise ValueError(\"Target is %s but average='binary'. Please \"\n\u001b[1;32m-> 1040\u001b[1;33m                              \"choose another average setting.\" % y_type)\n\u001b[0m\u001b[0;32m   1041\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mpos_label\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m         warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n",
      "\u001b[1;31mValueError\u001b[0m: Target is multiclass but average='binary'. Please choose another average setting."
     ]
    }
   ],
   "source": [
    "dte.fit(X_train, Y_train)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "\n",
    "Y_val_predict = dte.predict(X_val)\n",
    "\n",
    "print(\"Accuracy is {0:.2f}\".format(accuracy_score(Y_val, Y_val_predict)))\n",
    "print(\"Precision is {0:.2f}\".format(precision_score(Y_val, Y_val_predict)))\n",
    "print(\"Recall is {0:.2f}\".format(recall_score(Y_val, Y_val_predict)))\n",
    "print(\"AUC is {0:.2f}\".format(roc_auc_score(Y_val, Y_val_predict)))\n",
    "\n",
    "accuracy_dte = accuracy_score(Y_val, Y_val_predict)\n",
    "precision_dte = precision_score(Y_val, Y_val_predict)\n",
    "recall_dte = recall_score(Y_val, Y_val_predict)\n",
    "auc_dte = roc_auc_score(Y_val, Y_val_predict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
